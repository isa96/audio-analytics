{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- source : https://www.kdnuggets.com/2020/02/audio-data-analysis-deep-learning-python-part-2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import splitfolders\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data training-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1000 files [00:04, 233.06 files/s]\n"
     ]
    }
   ],
   "source": [
    "splitfolders.ratio('D:\\\\Script\\\\Kuliah\\\\Tesis\\\\tutorials\\\\data\\\\img_data\\\\',\n",
    "                   output='D:\\\\Script\\\\Kuliah\\\\Tesis\\\\tutorials\\\\data\\\\data\\\\',\n",
    "                   seed=1337,\n",
    "                   ratio=(0.8, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, # rescale all pixel values from 0-255, so aftre this step all our pixel values are in range (0,1)\n",
    "                                    shear_range=0.2, #to apply some random tranfromations\n",
    "                                    zoom_range=0.2, #to apply zoom\n",
    "                                    horizontal_flip=True) # image will be flipper horiztest_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 10 classes.\n",
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('D:\\\\Script\\\\Kuliah\\\\Tesis\\\\tutorials\\\\data\\\\data\\\\train\\\\',\n",
    "                                                target_size=(64, 64),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle = False)\n",
    "test_set = train_datagen.flow_from_directory('D:\\\\Script\\\\Kuliah\\\\Tesis\\\\tutorials\\\\data\\\\data\\\\val\\\\',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='categorical',\n",
    "                                            shuffle = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape=(64, 64, 3)\n",
    "\n",
    "#1st hidden layer\n",
    "model.add(Conv2D(32, (3, 3), strides=(2, 2), input_shape=input_shape))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#2nd hidden layer\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#3rd hidden layer\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Flatten\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "#Add fully connected layer.\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 31, 31, 32)        896       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_6 (Average (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 93,898\n",
      "Trainable params: 93,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.9\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 116s 1s/step - loss: 2.3431 - accuracy: 0.0294 - val_loss: 2.2838 - val_accuracy: 0.1013\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 109s 1s/step - loss: 2.3210 - accuracy: 0.0397 - val_loss: 2.3020 - val_accuracy: 0.0982\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 120s 1s/step - loss: 2.3216 - accuracy: 0.0325 - val_loss: 2.2960 - val_accuracy: 0.1013\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 113s 1s/step - loss: 2.3225 - accuracy: 0.0388 - val_loss: 2.2821 - val_accuracy: 0.1017\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 131s 1s/step - loss: 2.3234 - accuracy: 0.0306 - val_loss: 2.3065 - val_accuracy: 0.0978\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 120s 1s/step - loss: 2.3233 - accuracy: 0.0450 - val_loss: 2.2855 - val_accuracy: 0.1455\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 137s 1s/step - loss: 2.3232 - accuracy: 0.0512 - val_loss: 2.2749 - val_accuracy: 0.1154\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 123s 1s/step - loss: 2.3190 - accuracy: 0.0628 - val_loss: 2.3254 - val_accuracy: 0.1283\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 125s 1s/step - loss: 2.3314 - accuracy: 0.0425 - val_loss: 2.3029 - val_accuracy: 0.1003\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 130s 1s/step - loss: 2.3254 - accuracy: 0.0444 - val_loss: 2.3111 - val_accuracy: 0.1013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238db269f98>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=10,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.288435220718384, 0.09776536375284195]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "model.evaluate_generator(generator=test_set, steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 20s 395ms/step\n"
     ]
    }
   ],
   "source": [
    "test_set.reset()\n",
    "pred = model.predict_generator(test_set, steps=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices = np.argmax(pred, axis=1)\n",
    "\n",
    "labels = (training_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "predictions = predictions[:200]\n",
    "filenames = test_set.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200\n"
     ]
    }
   ],
   "source": [
    "print(len(filenames), len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['pred'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues\\blues00013.png</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues\\blues00021.png</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues\\blues00026.png</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues\\blues00039.png</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues\\blues00042.png</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>rock\\rock00084.png</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>rock\\rock00088.png</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>rock\\rock00090.png</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>rock\\rock00093.png</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>rock\\rock00096.png</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0  pred\n",
       "0    blues\\blues00013.png  jazz\n",
       "1    blues\\blues00021.png  jazz\n",
       "2    blues\\blues00026.png  jazz\n",
       "3    blues\\blues00039.png  jazz\n",
       "4    blues\\blues00042.png  jazz\n",
       "..                    ...   ...\n",
       "195    rock\\rock00084.png  jazz\n",
       "196    rock\\rock00088.png  jazz\n",
       "197    rock\\rock00090.png  jazz\n",
       "198    rock\\rock00093.png  jazz\n",
       "199    rock\\rock00096.png  jazz\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
